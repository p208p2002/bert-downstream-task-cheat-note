{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BertForQuestionAnswering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close transformers logging\n",
    "logging.getLogger(\"transformers.file_utils\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"transformers.configuration_utils\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_has_skip_token(check_tokens,skip_tokens):\n",
    "    for check_token in check_tokens:\n",
    "        for skip_token in skip_tokens:\n",
    "            if check_token == skip_token:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def _check_segment_type_is_a(start_index,end_index,segment_embeddings):\n",
    "    tag_segment_embeddings = segment_embeddings[start_index]\n",
    "    if 0 in tag_segment_embeddings:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def _get_best_indexes(logits, n_best_size):\n",
    "    \"\"\"Get the n-best logits from a list.\"\"\"\n",
    "    index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    best_indexes = []\n",
    "    for i in range(len(index_and_score)):\n",
    "        if i >= n_best_size:\n",
    "            break\n",
    "        best_indexes.append(index_and_score[i][0])\n",
    "    return best_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_model():\n",
    "    from transformers import BertTokenizer, AlbertForQuestionAnswering\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"clue/albert_chinese_small\")\n",
    "    albert = AlbertForQuestionAnswering.from_pretrained(\"clue/albert_chinese_small\")\n",
    "    return albert, tokenizer\n",
    "\n",
    "# ALBERT\n",
    "model, tokenizer = use_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 輸入(context、question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 4374, 1920, 3209, 3085,  818,  784, 7938,  102, 4374, 1920, 3209,\n",
      "         3221, 3413, 7269,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "context = '王大明是校長'\n",
    "question = '王大明擔任什麼'\n",
    "input_encode = tokenizer.encode_plus(question,context,add_special_tokens=True,return_tensors='pt')\n",
    "print(input_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_a_ids = (input_encode['token_type_ids'].squeeze(0) == 0).nonzero().transpose(0, 1).squeeze(0) # 找question長度\n",
    "len(segment_a_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 14\n"
     ]
    }
   ],
   "source": [
    "answer_padding = len(segment_a_ids) # 計算 [CLS]SEGMENT_A[SEP] 偏移量\n",
    "answer_start_position = 4 + answer_padding\n",
    "answer_end_position = 5 + answer_padding\n",
    "print(answer_start_position,answer_end_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "校 長\n"
     ]
    }
   ],
   "source": [
    "answer_start_id = input_encode['input_ids'][0][answer_start_position].item()\n",
    "answer_end_id = input_encode['input_ids'][0][answer_end_position].item()\n",
    "print(tokenizer.decode(answer_start_id),tokenizer.decode(answer_end_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13])\n",
      "tensor([14])\n"
     ]
    }
   ],
   "source": [
    "start_position_labels = torch.tensor([answer_start_position])\n",
    "end_position_labels = torch.tensor([answer_end_position])\n",
    "print(start_position_labels)\n",
    "print(end_position_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1783, -0.2392,  0.0243,  0.1509, -0.5761, -0.3853, -0.1867, -0.3440,\n",
      "         -0.3300, -0.0576,  0.1205,  0.2807,  0.3168,  0.1942,  0.0434,  0.0638]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "tensor([[ 0.0542,  0.0188, -0.1365,  0.3662,  0.0576, -0.1260, -0.1121, -0.1194,\n",
      "          0.1059, -0.0329, -0.2258,  0.4193, -0.2055,  0.1314,  0.2550,  0.2596]],\n",
      "       grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "loss, start_scores, end_scores = model(input_encode['input_ids'],token_type_ids=input_encode['token_type_ids'],\\\n",
    "                                start_positions= start_position_labels, end_positions= end_position_labels )\n",
    "print(start_scores)\n",
    "print(end_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 輸出、挑選答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16])\n",
      "torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "print(start_scores.shape)\n",
    "print(end_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 11, 13, 0, 3, 10, 15, 14, 2, 9]\n",
      "[11, 3, 15, 14, 13, 8, 4, 0, 1, 9]\n"
     ]
    }
   ],
   "source": [
    "predict_start_positions = _get_best_indexes(start_scores.squeeze(0),10)\n",
    "predict_end_positions = _get_best_indexes(end_scores.squeeze(0),10)\n",
    "print(predict_start_positions)\n",
    "print(predict_end_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scores = start_scores.squeeze(0)\n",
    "end_scores = end_scores.squeeze(0)\n",
    "answer_results=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是校長\n",
      "是校\n",
      "明\n",
      "明是校長\n",
      "明是校\n",
      "校長\n",
      "校\n",
      "大明\n",
      "大明是校長\n",
      "大明是校\n",
      "長\n",
      "王大明\n",
      "王大明是校長\n",
      "王大明是校\n",
      "王\n"
     ]
    }
   ],
   "source": [
    "for start_index in predict_start_positions:\n",
    "    for end_index in predict_end_positions:\n",
    "        answer_ids = input_encode['input_ids'].squeeze(0)[start_index:end_index+1]\n",
    "        answer_token = tokenizer.convert_ids_to_tokens(answer_ids)\n",
    "\n",
    "        if(len(answer_token) == 0 or len(answer_token)>30):\n",
    "            continue\n",
    "        elif(_check_has_skip_token(check_tokens = answer_token, skip_tokens = ['[CLS]','[SEP]','[PAD]'])):\n",
    "            continue\n",
    "        elif(_check_segment_type_is_a(start_index,end_index,input_encode['token_type_ids'].squeeze(0))):\n",
    "            continue\n",
    "        answer = \"\".join(answer_token)\n",
    "        print(answer)\n",
    "        answer_result = (start_index,start_scores[start_index].item(),end_index,end_scores[end_index].item(),answer)\n",
    "        answer_results.append(answer_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
